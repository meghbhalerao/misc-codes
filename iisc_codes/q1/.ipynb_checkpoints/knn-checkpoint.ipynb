{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time \n",
    "\n",
    "def DM(data_val,data_train):\n",
    "    dist_mat = np.zeros((data_train.shape[0],data_val.shape[0]))\n",
    "    for sample_val in range(data_val.shape[0]):\n",
    "        for sample_train in range(data_train.shape[0]):\n",
    "            dist_mat[sample_train,sample_val] = L2_distance(data_val[sample_val,1:],data_train[sample_train,1:])         \n",
    "    return dist_mat\n",
    "\n",
    "def L2_distance(mat1,mat2):\n",
    "    dist = np.linalg.norm(mat1-mat2)    \n",
    "    return dist\n",
    "\n",
    "def get_most_frequent(array):\n",
    "    counts = np.bincount(array)\n",
    "    return np.argmax(counts)\n",
    "\n",
    "something = 0\n",
    "def cosine_distance():\n",
    "    return something\n",
    "\n",
    "def normalize(matrix):\n",
    "    mean = np.mean(matrix.flatten())\n",
    "    sigma = np.std(matrix.flatten())\n",
    "    matrix = (matrix - mean)/sigma\n",
    "    return matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "data_train_full = np.loadtxt(\"/Users/megh/Work/misc/data/cifar-10-batches-py/txt_data/data_train.txt\")\n",
    "labels_train_full = np.loadtxt(\"/Users/megh/Work/misc/data/cifar-10-batches-py/txt_data/labels_train.txt\")\n",
    "data_test = np.loadtxt(\"/Users/megh/Work/misc/data/cifar-10-batches-py/txt_data/data_test.txt\")\n",
    "labels_test = np.loadtxt(\"/Users/megh/Work/misc/data/cifar-10-batches-py/txt_data/labels_test.txt\")\n",
    "end = time.time()\n",
    "print(\"Loading data took: \", (end-start)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding dimentions of labels for concatenation with image data\n",
    "labels_train_full = np.expand_dims(labels_train_full,axis=1)\n",
    "labels_test = np.expand_dims(labels_test,axis=1)\n",
    "# Defining the train and validation sets clearly\n",
    "data_train = data_train_full[0:45000,:]\n",
    "data_val = data_train_full[45000:50000,:]\n",
    "labels_train = labels_train_full[0:45000,:]\n",
    "labels_val = labels_train_full[45000:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of the data elements\n",
    "start = time.time()\n",
    "for row in range(data_train.shape[0]):\n",
    "    data_train[row,:] = normalize(data_train[row,:])  \n",
    "for row in range(data_test.shape[0]):\n",
    "    data_test[row,:] = normalize(data_test[row,:])  \n",
    "for row in range(data_val.shape[0]):\n",
    "    data_val[row,:] = normalize(data_val[row,:])  \n",
    "end = time.time()\n",
    "print(\"Normalizing data took: \", (end-start)/60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we obtain the distance matrix with respect to the training and validation set, this gives the distance between each of the validation elements with each of the training samples\n",
    "start = time.time()\n",
    "dist_mat_val = DM(data_val,data_train)\n",
    "end = time.time()\n",
    "print(\"Preparing distance matrix took: \", (end-start)/60, \" minutes\")\n",
    "sorted_dist_mat_val = np.zeros((data_train.shape[0],data_val.shape[0]))\n",
    "start = time.time()\n",
    "for val_element in range(dist_mat_val.shape[1]):\n",
    "    sorted_dist_mat_val[:,val_element] = np.argsort(dist_mat_val[:,val_element],axis=0)\n",
    "end = time.time()\n",
    "print(\"Preparing arg sorted distance matrix took: \", (end-start)/60, \" minutes\")\n",
    "# Using the K nearest neighbors to classify the data by using the actual class labels and the predicted class labels \n",
    "k = 5\n",
    "sorted_dist_mat_val = sorted_dist_mat_val[0:k,:]\n",
    "pred_mat_val  =  np.zeros((k,dist_mat_val.shape[1]))\n",
    "for column in range(sorted_dist_mat_val.shape[1]):\n",
    "    pred_mat_val[:,column] = labels_train[sorted_dist_mat_val[:,column].astype(int)][:,0]\n",
    "pred_val = []\n",
    "for column in range(pred_mat_val.shape[1]):\n",
    "    pred_val.append(get_most_frequent(pred_mat_val[:,column].astype(int)))\n",
    "\n",
    "pred_val =  np.array([pred_val]).T\n",
    "acc_vec_val =  (pred_val - labels_val_val).astype(int)\n",
    "acc_val = (pred_val.shape[0] - np.count_nonzero(acc_vec_val))/pred_val.shape[0]\n",
    "print(\"Accuracy on validation set of CIFAR-10 is: \",acc_val*100,\" percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy on the testing data\n",
    "start = time.time()\n",
    "dist_mat_test = DM(data_test,data_train)\n",
    "end = time.time()\n",
    "print(\"Preparing distance matrix took: \", (end-start)/60, \" minutes\")\n",
    "sorted_dist_mat_test = np.zeros((data_train.shape[0],data_test.shape[0]))\n",
    "start = time.time()\n",
    "for test_element in range(dist_mat_test.shape[1]):\n",
    "    sorted_dist_mat_test[:,test_element] = np.argsort(dist_mat_test[:,test_element],axis=0)\n",
    "end = time.time()\n",
    "print(\"Preparing arg sorted distance matrix took: \", (end-start)/60, \" minutes\")\n",
    "# Using the K nearest neighbors to classify the data by using the actual class labels and the predicted class labels \n",
    "k = 5\n",
    "sorted_dist_mat_test = sorted_dist_mat_test[0:k,:]\n",
    "pred_mat_test  =  np.zeros((k,dist_mat_test.shape[1]))\n",
    "for column in range(sorted_dist_mat_test.shape[1]):\n",
    "    pred_mat_test[:,column] = labels_train[sorted_dist_mat_test[:,column].astype(int)][:,0]\n",
    "    \n",
    "\n",
    "pred_test = []\n",
    "for column in range(pred_mat_test.shape[1]):\n",
    "    pred_test.append(get_most_frequent(pred_mat_test[:,column].astype(int)))\n",
    "\n",
    "pred_test =  np.array([pred_test]).T\n",
    "acc_vec_test =  (pred_test - labels_val_test).astype(int)\n",
    "acc_test = (pred_test.shape[0] - np.count_nonzero(acc_vec_test))/pred_test.shape[0]\n",
    "print(\"Accuracy on test set of CIFAR-10 is: \",acc_test*100,\" percent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
